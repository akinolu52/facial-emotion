{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af07b35da138af29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T20:32:04.718333Z",
     "start_time": "2025-02-28T20:32:04.703702Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Welcome to facial-emotion.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T20:32:11.943066Z",
     "start_time": "2025-02-28T20:32:04.775401Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scikitplot\n",
    "import seaborn as sns\n",
    "from keras.api.utils import to_categorical\n",
    "# from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization, LeakyReLU, Activation\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9497dc7b3156bd81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T20:32:17.843319Z",
     "start_time": "2025-02-28T20:32:12.392812Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/fer2013.csv')\n",
    "\n",
    "r, c = df.shape\n",
    "print(f'The dataset has {r} rows and {c} columns.\\n')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749bc32af51f58f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T20:32:18.003508Z",
     "start_time": "2025-02-28T20:32:17.996374Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Usage'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6168da9d02f9ea3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T20:32:18.193115Z",
     "start_time": "2025-02-28T20:32:18.188176Z"
    }
   },
   "outputs": [],
   "source": [
    "df['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06693862246ac8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T20:32:18.305563Z",
     "start_time": "2025-02-28T20:32:18.301071Z"
    }
   },
   "outputs": [],
   "source": [
    "df['emotion'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2b7ada3dd9390f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T20:32:19.995620Z",
     "start_time": "2025-02-28T20:32:19.977664Z"
    }
   },
   "outputs": [],
   "source": [
    "emotion_label_to_text = {0: 'anger', 1: 'disgust', 2: 'fear', 3: 'happiness', 4: 'sadness', 5: 'surprise', 6: 'neutral'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2c2e5dfdd1ea99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T20:32:20.174149Z",
     "start_time": "2025-02-28T20:32:20.155121Z"
    }
   },
   "outputs": [],
   "source": [
    "df.emotion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8e75573d0aee70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T20:32:23.463540Z",
     "start_time": "2025-02-28T20:32:23.139836Z"
    }
   },
   "outputs": [],
   "source": [
    "df['emotion'].map(emotion_label_to_text).value_counts().plot(kind='bar')\n",
    "\n",
    "plt.xlabel('Emotion')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Emotion Distribution')\n",
    "plt.xticks(rotation=45)  # Rotate the x-axis labels if needed for better visibility\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c70ba22b34b4c95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T20:32:28.374682Z",
     "start_time": "2025-02-28T20:32:23.558272Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(1, (14, 14))\n",
    "\n",
    "k = 0\n",
    "for label in sorted(df.emotion.unique()):\n",
    "    for j in range(7):\n",
    "        px = df[df.emotion == label].pixels.iloc[k]\n",
    "        px = np.array(px.split(' ')).reshape(48, 48).astype('float32')\n",
    "\n",
    "        k += 1\n",
    "        ax = plt.subplot(7, 7, k)\n",
    "        ax.imshow(px, cmap='gray')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title(emotion_label_to_text[label])\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e4d13dfa075fa5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T20:32:29.013464Z",
     "start_time": "2025-02-28T20:32:29.001488Z"
    }
   },
   "outputs": [],
   "source": [
    "math.sqrt(len(df.pixels[2].split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1672bcc5143247a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T20:32:29.068855Z",
     "start_time": "2025-02-28T20:32:29.054714Z"
    }
   },
   "outputs": [],
   "source": [
    "pixel_length = int(math.sqrt(len(df.pixels[1].split(' '))))\n",
    "\n",
    "pixel_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566031f983fdb6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T20:33:00.126390Z",
     "start_time": "2025-02-28T20:32:29.149084Z"
    }
   },
   "outputs": [],
   "source": [
    "img_array = df.pixels.apply(lambda x: np.array(x.split(' ')).reshape(pixel_length, pixel_length, 1).astype('float32'))\n",
    "img_array = np.stack(img_array, axis=0)\n",
    "\n",
    "img_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f668b99af956e4bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T20:33:00.175453Z",
     "start_time": "2025-02-28T20:33:00.166079Z"
    }
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "img_labels = le.fit_transform(df.emotion)\n",
    "img_labels = to_categorical(img_labels)\n",
    "\n",
    "img_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbe0faedd23483c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T20:33:00.217754Z",
     "start_time": "2025-02-28T20:33:00.214043Z"
    }
   },
   "outputs": [],
   "source": [
    "le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "\n",
    "le_name_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd7e95a247de477",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T20:33:00.659634Z",
     "start_time": "2025-02-28T20:33:00.265739Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(img_array, img_labels, shuffle=True, stratify=img_labels,\n",
    "                                                    test_size=0.1, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb8361ad28275dba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T20:33:00.671990Z",
     "start_time": "2025-02-28T20:33:00.670354Z"
    }
   },
   "outputs": [],
   "source": [
    "# del df\n",
    "# del img_array\n",
    "# del img_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6739e668f59391d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T20:33:00.697447Z",
     "start_time": "2025-02-28T20:33:00.694630Z"
    }
   },
   "outputs": [],
   "source": [
    "_, img_width, img_height, img_depth = X_train.shape\n",
    "num_classes = y_train.shape[1]\n",
    "\n",
    "img_width, img_height, img_depth, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca888c55fbb50422",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T20:33:00.706482Z",
     "start_time": "2025-02-28T20:33:00.704739Z"
    }
   },
   "outputs": [],
   "source": [
    "# np.random.seed(42)\n",
    "# surprise_idx = np.random.choice(np.where(y_train[:, 0] == 1)[0], size=1)\n",
    "# happy_idx = np.random.choice(np.where(y_train[:, 1] == 1)[0], size=1)\n",
    "# anger_idx = np.random.choice(np.where(y_train[:, 2] == 1)[0], size=1)\n",
    "# sad_idx = np.random.choice(np.where(y_train[:, 3] == 1)[0], size=1)\n",
    "# fear_idx = np.random.choice(np.where(y_train[:, 4] == 1)[0], size=1)\n",
    "#\n",
    "# fig = plt.figure(1, (6, 13))\n",
    "#\n",
    "# i = 0\n",
    "# for name, idx in zip(label_emotion_mapper.values(), [surprise_idx, happy_idx, anger_idx, sad_idx, fear_idx]):\n",
    "#     for j in range(3):\n",
    "#         i += 1\n",
    "#         ax = plt.subplot(5, 3, i)\n",
    "#         sample_img = X_train[idx][0, j, :, :, 0]\n",
    "#         ax.imshow(sample_img, cmap='gray')\n",
    "#         ax.set_xticks([])\n",
    "#         ax.set_yticks([])\n",
    "#         ax.set_title(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddefcc18bf39011e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T20:33:01.063269Z",
     "start_time": "2025-02-28T20:33:00.744413Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalizing results, as neural networks are very sensitive to un-normalized data.\n",
    "X_train = X_train / 255.\n",
    "X_valid = X_test / 255.\n",
    "\n",
    "X_train.mean(), X_train.std(), X_valid.mean(), X_valid.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79f69702df4b16a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T20:33:01.079299Z",
     "start_time": "2025-02-28T20:33:01.070247Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_net(optim):\n",
    "    \"\"\"\n",
    "    This is a Deep Convolutional Neural Network (DCNN). For generalization purpose I used dropouts in regular intervals.\n",
    "    I used `ELU` as the activation because it avoids dying relu problem but also performed well as compared to LeakyRelu\n",
    "    at least in this case. `he_normal` kernel initializer is used as it suits ELU. BatchNormalization is also used for better\n",
    "    results.\n",
    "    \"\"\"\n",
    "    net = Sequential(name='DCNN')\n",
    "\n",
    "    # Use Input layer for defining the input shape\n",
    "    net.add(\n",
    "        Input(shape=(img_width, img_height, img_depth), name='input_layer')\n",
    "    )\n",
    "\n",
    "    net.add(\n",
    "        Conv2D(\n",
    "            filters=64,\n",
    "            kernel_size=(5, 5),\n",
    "            activation='elu',\n",
    "            padding='same',\n",
    "            kernel_initializer='he_normal',\n",
    "            name='conv2d_1'\n",
    "        )\n",
    "    )\n",
    "    net.add(BatchNormalization(name='batchnorm_1'))\n",
    "    net.add(\n",
    "        Conv2D(\n",
    "            filters=64,\n",
    "            kernel_size=(5, 5),\n",
    "            activation='elu',\n",
    "            padding='same',\n",
    "            kernel_initializer='he_normal',\n",
    "            name='conv2d_2'\n",
    "        )\n",
    "    )\n",
    "    net.add(BatchNormalization(name='batchnorm_2'))\n",
    "\n",
    "    net.add(MaxPooling2D(pool_size=(2, 2), name='maxpool2d_1'))\n",
    "    net.add(Dropout(0.4, name='dropout_1'))\n",
    "\n",
    "    net.add(\n",
    "        Conv2D(\n",
    "            filters=128,\n",
    "            kernel_size=(3, 3),\n",
    "            activation='elu',\n",
    "            padding='same',\n",
    "            kernel_initializer='he_normal',\n",
    "            name='conv2d_3'\n",
    "        )\n",
    "    )\n",
    "    net.add(BatchNormalization(name='batchnorm_3'))\n",
    "    net.add(\n",
    "        Conv2D(\n",
    "            filters=128,\n",
    "            kernel_size=(3, 3),\n",
    "            activation='elu',\n",
    "            padding='same',\n",
    "            kernel_initializer='he_normal',\n",
    "            name='conv2d_4'\n",
    "        )\n",
    "    )\n",
    "    net.add(BatchNormalization(name='batchnorm_4'))\n",
    "\n",
    "    net.add(MaxPooling2D(pool_size=(2, 2), name='maxpool2d_2'))\n",
    "    net.add(Dropout(0.4, name='dropout_2'))\n",
    "\n",
    "    net.add(\n",
    "        Conv2D(\n",
    "            filters=256,\n",
    "            kernel_size=(3, 3),\n",
    "            activation='elu',\n",
    "            padding='same',\n",
    "            kernel_initializer='he_normal',\n",
    "            name='conv2d_5'\n",
    "        )\n",
    "    )\n",
    "    net.add(BatchNormalization(name='batchnorm_5'))\n",
    "    net.add(\n",
    "        Conv2D(\n",
    "            filters=256,\n",
    "            kernel_size=(3, 3),\n",
    "            activation='elu',\n",
    "            padding='same',\n",
    "            kernel_initializer='he_normal',\n",
    "            name='conv2d_6'\n",
    "        )\n",
    "    )\n",
    "    net.add(BatchNormalization(name='batchnorm_6'))\n",
    "\n",
    "    net.add(MaxPooling2D(pool_size=(2, 2), name='maxpool2d_3'))\n",
    "    net.add(Dropout(0.5, name='dropout_3'))\n",
    "\n",
    "    net.add(Flatten(name='flatten'))\n",
    "\n",
    "    net.add(\n",
    "        Dense(\n",
    "            128,\n",
    "            activation='elu',\n",
    "            kernel_initializer='he_normal',\n",
    "            name='dense_1'\n",
    "        )\n",
    "    )\n",
    "    net.add(BatchNormalization(name='batchnorm_7'))\n",
    "\n",
    "    net.add(Dropout(0.6, name='dropout_4'))\n",
    "\n",
    "    net.add(\n",
    "        Dense(\n",
    "            num_classes,\n",
    "            activation='softmax',\n",
    "            name='out_layer'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    net.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=optim,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    net.summary()\n",
    "\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc9e68e8c1892250",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T20:33:01.100990Z",
     "start_time": "2025-02-28T20:33:01.098483Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "I used two callbacks one is `early stopping` for avoiding overfitting training data\n",
    "and other `ReduceLROnPlateau` for learning rate.\n",
    "\"\"\"\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    min_delta=0.00005,\n",
    "    patience=11,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',\n",
    "    factor=0.5,\n",
    "    patience=7,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    early_stopping,\n",
    "    lr_scheduler,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3407f860f890851",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T20:33:01.149896Z",
     "start_time": "2025-02-28T20:33:01.112405Z"
    }
   },
   "outputs": [],
   "source": [
    "# As the data in hand is less as compared to the task so ImageDataGenerator is good to go.\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    shear_range=0.15,\n",
    "    zoom_range=0.15,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "train_datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba4c0cdeef30821",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-02-28T20:33:01.153830Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32  # batch size of 32 performs the best.\n",
    "epochs = 10  # should be 100\n",
    "optims = [\n",
    "    optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name='Nadam'),\n",
    "    optimizers.Adam(0.001),\n",
    "]\n",
    "\n",
    "# I tried both `Nadam` and `Adam`, the difference in results is not different but I finally went with Nadam as it is more popular.\n",
    "model = build_net(optims[1])\n",
    "# history = model.fit_generator(\n",
    "history = model.fit(\n",
    "    train_datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "    validation_data=(X_valid, y_test),\n",
    "    steps_per_epoch=len(X_train) // batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    # workers=4,\n",
    "    # use_multiprocessing=True,\n",
    "    # max_queue_size=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca00d9c106104",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"facial-model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cb8224543a2e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "\n",
    "# Create the figure and subplots\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Accuracy plot\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "sns.lineplot(x=history.epoch, y=history.history['accuracy'], label='train')\n",
    "sns.lineplot(x=history.epoch, y=history.history['val_accuracy'], label='valid')\n",
    "plt.title('Accuracy')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Loss plot\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "sns.lineplot(x=history.epoch, y=history.history['loss'], label='train')\n",
    "sns.lineplot(x=history.epoch, y=history.history['val_loss'], label='valid')\n",
    "plt.title('Loss')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot and display it\n",
    "plt.savefig('epoch_history_dcnn.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12f5b44b8676def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes for accuracy and loss\n",
    "df_accu = pd.DataFrame({'train': history.history['accuracy'], 'valid': history.history['val_accuracy']})\n",
    "df_loss = pd.DataFrame({'train': history.history['loss'], 'valid': history.history['val_loss']})\n",
    "\n",
    "# Create the figure and subplots\n",
    "fig = plt.figure(figsize=(14, 4))\n",
    "\n",
    "# Accuracy plot\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "sns.violinplot(x=\"variable\", y=\"value\", data=pd.melt(df_accu))\n",
    "plt.title('Accuracy')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Loss plot\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "sns.violinplot(x=\"variable\", y=\"value\", data=pd.melt(df_loss))\n",
    "plt.title('Loss')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot and display it\n",
    "plt.savefig('performance_dist.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b202046000a2218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities for each class using the model\n",
    "yhat_test = model.predict(X_test)\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "yhat_test_classes = np.argmax(yhat_test, axis=1)\n",
    "\n",
    "# Plot confusion matrix\n",
    "scikitplot.metrics.plot_confusion_matrix(np.argmax(y_test, axis=1), yhat_test_classes, figsize=(7, 7))\n",
    "plt.savefig(\"confusion_matrix_dcnn.png\")\n",
    "\n",
    "# Print the number of incorrect predictions\n",
    "print(f'Total wrong test predictions: {np.sum(np.argmax(y_test, axis=1) != yhat_test_classes)}\\n\\n')\n",
    "\n",
    "# Print classification report with zero_division parameter to handle the warning\n",
    "print(classification_report(np.argmax(y_test, axis=1), yhat_test_classes, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80511ec1d3fe7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "np.random.seed(2)\n",
    "\n",
    "# Randomly select sad and neutral images\n",
    "random_sad_imgs = np.random.choice(np.where(y_test[:, 4] == 1)[0], size=9)\n",
    "random_neutral_imgs = np.random.choice(np.where(y_test[:, 6] == 1)[0], size=9)\n",
    "\n",
    "# Create the figure\n",
    "fig = plt.figure(1, (18, 4))\n",
    "\n",
    "# Loop through the selected indices\n",
    "for i, (sadidx, neuidx) in enumerate(zip(random_sad_imgs, random_neutral_imgs)):\n",
    "    # Plot sad images\n",
    "    ax = plt.subplot(2, 9, i + 1)\n",
    "    sample_img = X_valid[sadidx, :, :, 0]\n",
    "    ax.imshow(sample_img, cmap='gray')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    # Predict and get the label for sad images\n",
    "    pred_sad = model.predict(sample_img.reshape(1, 48, 48, 1))\n",
    "    predicted_label_sad = emotion_label_to_text[np.argmax(pred_sad)]  # Use np.argmax to get the predicted class index\n",
    "    ax.set_title(f\"true:sad, pred:{predicted_label_sad}\")\n",
    "\n",
    "    # Plot neutral images\n",
    "    ax = plt.subplot(2, 9, i + 10)\n",
    "    sample_img = X_valid[neuidx, :, :, 0]\n",
    "    ax.imshow(sample_img, cmap='gray')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    # Predict and get the label for neutral images\n",
    "    pred_neutral = model.predict(sample_img.reshape(1, 48, 48, 1))\n",
    "    predicted_label_neutral = emotion_label_to_text[\n",
    "        np.argmax(pred_neutral)]  # Use np.argmax to get the predicted class index\n",
    "    ax.set_title(f\"t:neut, p:{predicted_label_neutral}\")\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b506458c4d75d0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def plot_random_emotion_predictions(model, X_valid, y_test, emotion_label_to_text, emotion_name, n_images=9, seed=2):\n",
    "    # Ensure reproducibility with the random seed\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Find the index of the emotion in the label dictionary\n",
    "    emotion_idx = [idx for idx, label in emotion_label_to_text.items() if label == emotion_name]\n",
    "\n",
    "    if not emotion_idx:\n",
    "        print(f\"Emotion '{emotion_name}' not found in the emotion_label_to_text dictionary.\")\n",
    "        return\n",
    "\n",
    "    emotion_idx = emotion_idx[0]  # Get the first index (since the dictionary is unique)\n",
    "\n",
    "    # Select random indices for the chosen emotion\n",
    "    random_emotion_imgs = np.random.choice(np.where(y_test[:, emotion_idx] == 1)[0], size=n_images)\n",
    "\n",
    "    # Create the figure for plotting\n",
    "    fig = plt.figure(figsize=(18, 4))\n",
    "\n",
    "    # Loop through the selected indices and plot\n",
    "    for i, idx in enumerate(random_emotion_imgs):\n",
    "        # Plot the image\n",
    "        ax = plt.subplot(1, n_images, i + 1)\n",
    "        sample_img = X_valid[idx, :, :, 0]\n",
    "        ax.imshow(sample_img, cmap='gray')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "        # Predict and get the label for the current image\n",
    "        pred = model.predict(sample_img.reshape(1, 48, 48, 1))\n",
    "        predicted_label = emotion_label_to_text[np.argmax(pred)]  # Get predicted label using np.argmax\n",
    "\n",
    "        # Set the title with the predicted label\n",
    "        ax.set_title(f\"pred:{predicted_label}\")\n",
    "\n",
    "        # Add the emotion name at the bottom of the image\n",
    "        ax.text(0.5, -0.1, f\"emotion:{emotion_name}\", ha='center', va='center', transform=ax.transAxes, fontsize=10)\n",
    "\n",
    "    # Adjust layout and show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for emotion in emotion_label_to_text.values():\n",
    "    # Call the function to plot for the emotion \"--\"\n",
    "    plot_random_emotion_predictions(model, X_valid, y_test, emotion_label_to_text, emotion_name=emotion, n_images=9,\n",
    "                                    seed=2)\n",
    "    # break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebae0d0f3a445b1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T19:29:19.174115Z",
     "start_time": "2025-02-28T19:27:57.250310Z"
    }
   },
   "outputs": [],
   "source": [
    "# Part I of the assignment\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 1: Sample a subset of the data based on class label\n",
    "# Let's choose happiness (3) and sadness (4) as our two classes for Part I\n",
    "\n",
    "# Extract features from the existing dataset\n",
    "# Assuming df, emotion_label_to_text, X_train, y_train, X_test, y_test are already defined\n",
    "\n",
    "# Get indices for happiness and sadness from training data\n",
    "happiness_indices = np.where(np.argmax(y_train, axis=1) == 3)[0]\n",
    "sadness_indices = np.where(np.argmax(y_train, axis=1) == 4)[0]\n",
    "\n",
    "# Sample equal amounts from each class (use the smaller class size)\n",
    "sample_size = min(len(happiness_indices), len(sadness_indices))\n",
    "happiness_sample = np.random.choice(happiness_indices, size=sample_size, replace=False)\n",
    "sadness_sample = np.random.choice(sadness_indices, size=sample_size, replace=False)\n",
    "\n",
    "# Combine indices and extract the subset\n",
    "subset_indices = np.concatenate([happiness_sample, sadness_sample])\n",
    "X_subset = X_train[subset_indices].reshape(len(subset_indices), -1)  # Flatten images\n",
    "y_subset = np.argmax(y_train[subset_indices], axis=1)\n",
    "# Convert class labels 3 and 4 to binary labels 0 and 1\n",
    "y_subset = np.where(y_subset == 3, 0, 1)  # happiness = 0, sadness = 1\n",
    "\n",
    "# Do the same for test data\n",
    "happiness_test_indices = np.where(np.argmax(y_test, axis=1) == 3)[0]\n",
    "sadness_test_indices = np.where(np.argmax(y_test, axis=1) == 4)[0]\n",
    "test_indices = np.concatenate([happiness_test_indices, sadness_test_indices])\n",
    "X_test_subset = X_test[test_indices].reshape(len(test_indices), -1)\n",
    "y_test_subset = np.argmax(y_test[test_indices], axis=1)\n",
    "y_test_subset = np.where(y_test_subset == 3, 0, 1)\n",
    "\n",
    "# Step 2: Apply PCA and LDA and visualize the results\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_subset_scaled = scaler.fit_transform(X_subset)\n",
    "X_test_subset_scaled = scaler.transform(X_test_subset)\n",
    "\n",
    "# Apply PCA\n",
    "n_components = 50  # Choose a reasonable number of components\n",
    "pca = PCA(n_components=n_components)\n",
    "X_pca = pca.fit_transform(X_subset_scaled)\n",
    "X_test_pca = pca.transform(X_test_subset_scaled)\n",
    "\n",
    "# Plot the explained variance ratio\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('PCA: Explained Variance vs. Number of Components')\n",
    "plt.grid(True)\n",
    "plt.savefig('pca_explained_variance.png')\n",
    "plt.show()\n",
    "\n",
    "# Apply LDA (for visualization, we need only 1 component since we have 2 classes)\n",
    "lda = LDA(n_components=1)\n",
    "X_lda = lda.fit_transform(X_subset_scaled, y_subset)\n",
    "X_test_lda = lda.transform(X_test_subset_scaled)\n",
    "\n",
    "# Visualize the top 2 PCA components\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_subset, cmap='viridis', alpha=0.7)\n",
    "plt.title('PCA: First Two Principal Components')\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 2')\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=['Happiness', 'Sadness'])\n",
    "plt.grid(True)\n",
    "\n",
    "# Visualize LDA projection\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(data=pd.DataFrame({\n",
    "    'LDA': X_lda.flatten(),\n",
    "    'Emotion': y_subset\n",
    "}), x=\"LDA\", hue=\"Emotion\", bins=50, kde=True, element=\"step\", palette=\"viridis\", common_norm=False)\n",
    "\n",
    "plt.title('LDA Projection')\n",
    "plt.xlabel('LD 1')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('pca_lda_visualization.png')\n",
    "plt.show()\n",
    "\n",
    "# Step 3: Perform classification using naÃ¯ve Bayes and interpret the results\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_pca, y_subset)\n",
    "y_pred_nb = nb_classifier.predict(X_test_pca)\n",
    "y_pred_proba_nb = nb_classifier.predict_proba(X_test_pca)\n",
    "\n",
    "print(\"Naive Bayes Classification Report:\")\n",
    "print(classification_report(y_test_subset, y_pred_nb))\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test_subset, y_pred_nb))\n",
    "\n",
    "# Visualize confusion matrix for Naive Bayes\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test_subset, y_pred_nb)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Happiness', 'Sadness'],\n",
    "            yticklabels=['Happiness', 'Sadness'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Naive Bayes Confusion Matrix')\n",
    "plt.savefig('naive_bayes_cm.png')\n",
    "plt.show()\n",
    "\n",
    "# Step 4: Perform classification using Logistic Regression and interpret the results\n",
    "lr_classifier = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_classifier.fit(X_pca, y_subset)\n",
    "y_pred_lr = lr_classifier.predict(X_test_pca)\n",
    "y_pred_proba_lr = lr_classifier.predict_proba(X_test_pca)\n",
    "\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test_subset, y_pred_lr))\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test_subset, y_pred_lr))\n",
    "\n",
    "# Visualize confusion matrix for Logistic Regression\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test_subset, y_pred_lr)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Happiness', 'Sadness'],\n",
    "            yticklabels=['Happiness', 'Sadness'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Logistic Regression Confusion Matrix')\n",
    "plt.savefig('logistic_regression_cm.png')\n",
    "plt.show()\n",
    "\n",
    "# Step 5: Perform classification using SVMs and interpret the results\n",
    "svm_classifier = SVC(probability=True, random_state=42)\n",
    "svm_classifier.fit(X_pca, y_subset)\n",
    "y_pred_svm = svm_classifier.predict(X_test_pca)\n",
    "y_pred_proba_svm = svm_classifier.predict_proba(X_test_pca)\n",
    "\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test_subset, y_pred_svm))\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test_subset, y_pred_svm))\n",
    "\n",
    "# Visualize confusion matrix for SVM\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test_subset, y_pred_svm)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Happiness', 'Sadness'],\n",
    "            yticklabels=['Happiness', 'Sadness'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('SVM Confusion Matrix')\n",
    "plt.savefig('svm_cm.png')\n",
    "plt.show()\n",
    "\n",
    "# Step f: Compare confidence of class assignments\n",
    "# Select a few test samples\n",
    "test_samples = X_test_subset_scaled[:10]  # First 10 test samples\n",
    "test_pca = pca.transform(test_samples)\n",
    "\n",
    "# Get probability predictions from all classifiers\n",
    "proba_nb = nb_classifier.predict_proba(test_pca)\n",
    "proba_lr = lr_classifier.predict_proba(test_pca)\n",
    "proba_svm = svm_classifier.predict_proba(test_pca)\n",
    "\n",
    "# Combine the probabilities for visualization\n",
    "probabilities = pd.DataFrame({\n",
    "    'True Label': ['Happiness' if l == 0 else 'Sadness' for l in y_test_subset[:10]],\n",
    "    'NB Happiness': proba_nb[:, 0],\n",
    "    'NB Sadness': proba_nb[:, 1],\n",
    "    'LR Happiness': proba_lr[:, 0],\n",
    "    'LR Sadness': proba_lr[:, 1],\n",
    "    'SVM Happiness': proba_svm[:, 0],\n",
    "    'SVM Sadness': proba_svm[:, 1]\n",
    "})\n",
    "\n",
    "# Plot the confidence levels\n",
    "plt.figure(figsize=(12, 8))\n",
    "bar_width = 0.25\n",
    "index = np.arange(len(probabilities))\n",
    "\n",
    "plt.bar(index, probabilities['NB Happiness'], bar_width, label='NB Happiness', color='skyblue')\n",
    "plt.bar(index, probabilities['NB Sadness'], bar_width, bottom=probabilities['NB Happiness'], label='NB Sadness',\n",
    "        color='navy')\n",
    "\n",
    "plt.bar(index + bar_width, probabilities['LR Happiness'], bar_width, label='LR Happiness', color='lightgreen')\n",
    "plt.bar(index + bar_width, probabilities['LR Sadness'], bar_width, bottom=probabilities['LR Happiness'],\n",
    "        label='LR Sadness', color='darkgreen')\n",
    "\n",
    "plt.bar(index + 2 * bar_width, probabilities['SVM Happiness'], bar_width, label='SVM Happiness', color='salmon')\n",
    "plt.bar(index + 2 * bar_width, probabilities['SVM Sadness'], bar_width, bottom=probabilities['SVM Happiness'],\n",
    "        label='SVM Sadness', color='darkred')\n",
    "\n",
    "plt.xlabel('Test Sample')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Comparison of Confidence Levels by Classifier')\n",
    "plt.xticks(index + bar_width, [f'Sample {i + 1}\\n{label}' for i, label in enumerate(probabilities['True Label'])])\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('confidence_comparison.png')\n",
    "plt.show()\n",
    "\n",
    "# Plot a more detailed view of probabilities for a single classifier\n",
    "plt.figure(figsize=(12, 6))\n",
    "sample_indices = range(len(probabilities))\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.bar(sample_indices, proba_svm[:, 0], label='Happiness', color='lightblue', alpha=0.7)\n",
    "plt.bar(sample_indices, proba_svm[:, 1], bottom=proba_svm[:, 0], label='Sadness', color='orange', alpha=0.7)\n",
    "plt.ylabel('Probability')\n",
    "plt.title('SVM Confidence Levels (How Happy vs How Sad)')\n",
    "plt.xticks(sample_indices, [f'Sample {i + 1}\\n{label}' for i, label in enumerate(probabilities['True Label'])])\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('svm_confidence_levels.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e11f0d47c9c0ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-28T19:38:34.307493Z",
     "start_time": "2025-02-28T19:29:58.260452Z"
    }
   },
   "outputs": [],
   "source": [
    "# Part II of the assignment\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Use all emotion classes for Part II\n",
    "# Flatten the images for feature extraction\n",
    "X_all = X_train.reshape(X_train.shape[0], -1)\n",
    "y_all = np.argmax(y_train, axis=1)\n",
    "\n",
    "X_test_all = X_test.reshape(X_test.shape[0], -1)\n",
    "y_test_all = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Standardize the data\n",
    "scaler_all = StandardScaler()\n",
    "X_all_scaled = scaler_all.fit_transform(X_all)\n",
    "X_test_all_scaled = scaler_all.transform(X_test_all)\n",
    "\n",
    "# Step 1: Apply PCA and LDA\n",
    "# PCA analysis\n",
    "n_components_all = 50\n",
    "pca_all = PCA(n_components=n_components_all)\n",
    "X_pca_all = pca_all.fit_transform(X_all_scaled)\n",
    "X_test_pca_all = pca_all.transform(X_test_all_scaled)\n",
    "\n",
    "# Plot the incremental gain in capturing variance\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(np.cumsum(pca_all.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('PCA: Full Dataset')\n",
    "plt.grid(True)\n",
    "\n",
    "# Compare with the subset\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('PCA: Subset (Happiness/Sadness)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('pca_comparison.png')\n",
    "plt.show()\n",
    "\n",
    "# LDA analysis (for all emotions, we can have up to n_classes-1 components)\n",
    "lda_all = LDA(n_components=min(6, len(np.unique(y_all)) - 1))  # 7 classes, so up to 6 components\n",
    "X_lda_all = lda_all.fit_transform(X_all_scaled, y_all)\n",
    "X_test_lda_all = lda_all.transform(X_test_all_scaled)\n",
    "\n",
    "# Visualize the first two LDA components\n",
    "plt.figure(figsize=(10, 8))\n",
    "for emotion, i in emotion_label_to_text.items():\n",
    "    plt.scatter(X_lda_all[y_all == emotion, 0], X_lda_all[y_all == emotion, 1],\n",
    "                alpha=0.7, label=emotion_label_to_text[emotion])\n",
    "plt.xlabel('LD 1')\n",
    "plt.ylabel('LD 2')\n",
    "plt.title('LDA: First Two Components by Emotion')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('lda_all_emotions.png')\n",
    "plt.show()\n",
    "\n",
    "# Step 2: Naive Bayes classification\n",
    "nb_classifier_all = GaussianNB()\n",
    "nb_classifier_all.fit(X_pca_all, y_all)\n",
    "y_pred_nb_all = nb_classifier_all.predict(X_test_pca_all)\n",
    "\n",
    "print(\"Naive Bayes Classification Report (All Emotions):\")\n",
    "print(classification_report(y_test_all, y_pred_nb_all))\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test_all, y_pred_nb_all))\n",
    "\n",
    "# Visualize confusion matrix for Naive Bayes\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm_nb = confusion_matrix(y_test_all, y_pred_nb_all)\n",
    "sns.heatmap(cm_nb, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=[emotion_label_to_text[i] for i in range(7)],\n",
    "            yticklabels=[emotion_label_to_text[i] for i in range(7)])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Naive Bayes Confusion Matrix (All Emotions)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('nb_confusion_matrix_all.png')\n",
    "plt.show()\n",
    "\n",
    "# Step 3: Logistic Regression classification\n",
    "lr_classifier_all = LogisticRegression(max_iter=1000, multi_class='multinomial', random_state=42)\n",
    "lr_classifier_all.fit(X_pca_all, y_all)\n",
    "y_pred_lr_all = lr_classifier_all.predict(X_test_pca_all)\n",
    "\n",
    "print(\"Logistic Regression Classification Report (All Emotions):\")\n",
    "print(classification_report(y_test_all, y_pred_lr_all))\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test_all, y_pred_lr_all))\n",
    "\n",
    "# Visualize confusion matrix for Logistic Regression\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm_lr = confusion_matrix(y_test_all, y_pred_lr_all)\n",
    "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=[emotion_label_to_text[i] for i in range(7)],\n",
    "            yticklabels=[emotion_label_to_text[i] for i in range(7)])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Logistic Regression Confusion Matrix (All Emotions)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('lr_confusion_matrix_all.png')\n",
    "plt.show()\n",
    "\n",
    "# Step 4: SVM classification\n",
    "# Using a smaller C value for better generalization with multiple classes\n",
    "svm_classifier_all = SVC(probability=True, C=1.0, kernel='rbf', random_state=42)\n",
    "svm_classifier_all.fit(X_pca_all, y_all)\n",
    "y_pred_svm_all = svm_classifier_all.predict(X_test_pca_all)\n",
    "\n",
    "print(\"SVM Classification Report (All Emotions):\")\n",
    "print(classification_report(y_test_all, y_pred_svm_all))\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test_all, y_pred_svm_all))\n",
    "\n",
    "# Visualize confusion matrix for SVM\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm_svm = confusion_matrix(y_test_all, y_pred_svm_all)\n",
    "sns.heatmap(cm_svm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=[emotion_label_to_text[i] for i in range(7)],\n",
    "            yticklabels=[emotion_label_to_text[i] for i in range(7)])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('SVM Confusion Matrix (All Emotions)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('svm_confusion_matrix_all.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Step 5: Discuss which classes are most similar/different\n",
    "# Calculate similarity matrix based on misclassifications\n",
    "def calculate_similarity_matrix(confusion_matrix):\n",
    "    # Normalize by row totals to get percentages\n",
    "    row_sums = confusion_matrix.sum(axis=1)\n",
    "    normalized_cm = confusion_matrix / row_sums[:, np.newaxis]\n",
    "\n",
    "    # The diagonal represents correct classifications, so zero it out\n",
    "    np.fill_diagonal(normalized_cm, 0)\n",
    "\n",
    "    # Now the matrix shows how often each class is mistaken for others\n",
    "    return normalized_cm\n",
    "\n",
    "\n",
    "# Get similarity matrices from the different models\n",
    "similarity_nb = calculate_similarity_matrix(cm_nb)\n",
    "similarity_lr = calculate_similarity_matrix(cm_lr)\n",
    "similarity_svm = calculate_similarity_matrix(cm_svm)\n",
    "\n",
    "# Average the similarities across models\n",
    "average_similarity = (similarity_nb + similarity_lr + similarity_svm) / 3\n",
    "\n",
    "# Visualize the similarity matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(average_similarity, annot=True, fmt='.2f', cmap='YlOrRd',\n",
    "            xticklabels=[emotion_label_to_text[i] for i in range(7)],\n",
    "            yticklabels=[emotion_label_to_text[i] for i in range(7)])\n",
    "plt.xlabel('Confused With')\n",
    "plt.ylabel('True Emotion')\n",
    "plt.title('Inter-class Confusion (Average of NB, LR, SVM)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('emotion_similarity_matrix.png')\n",
    "plt.show()\n",
    "\n",
    "# Step 6: Identify potentially mislabeled faces\n",
    "# Approach: Use confidence scores from the best classifier (SVM) to find samples where\n",
    "# the model's prediction differs from the label with high confidence\n",
    "\n",
    "# Get probability predictions for test data\n",
    "test_probs = svm_classifier_all.predict_proba(X_test_pca_all)\n",
    "\n",
    "# Calculate confidence scores\n",
    "max_probs = np.max(test_probs, axis=1)  # Highest probability for each prediction\n",
    "pred_classes = np.argmax(test_probs, axis=1)  # Predicted class for each sample\n",
    "\n",
    "# Find potentially mislabeled samples (high confidence but wrong prediction)\n",
    "confidence_threshold = 0.8  # High confidence threshold\n",
    "mislabeled_candidates = np.where((pred_classes != y_test_all) & (max_probs > confidence_threshold))[0]\n",
    "\n",
    "# Let's visualize some of these potentially mislabeled faces\n",
    "if len(mislabeled_candidates) > 0:\n",
    "    n_samples = min(len(mislabeled_candidates), 10)  # Display up to 10 examples\n",
    "    selected_indices = mislabeled_candidates[:n_samples]\n",
    "\n",
    "    plt.figure(figsize=(15, n_samples * 2))\n",
    "    for i, idx in enumerate(selected_indices):\n",
    "        plt.subplot(n_samples, 1, i + 1)\n",
    "        # Reshape back to the image dimensions\n",
    "        img = X_test[idx].reshape(48, 48)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(f\"Labeled as: {emotion_label_to_text[y_test_all[idx]]}, \"\n",
    "                  f\"Predicted as: {emotion_label_to_text[pred_classes[idx]]} \"\n",
    "                  f\"with {max_probs[idx]:.2f} confidence\")\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('potential_mislabeled_faces.png')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No strong candidates for mislabeled faces found.\")\n",
    "\n",
    "\n",
    "# Function to identify mislabeled examples in the dataset\n",
    "def identify_mislabeled_faces(classifier, X_features, y_labels, confidence_threshold=0.8):\n",
    "    \"\"\"\n",
    "    Identifies potentially mislabeled faces based on classifier confidence.\n",
    "\n",
    "    Parameters:\n",
    "    - classifier: Trained classifier with predict_proba method\n",
    "    - X_features: Feature matrix\n",
    "    - y_labels: True labels\n",
    "    - confidence_threshold: Minimum confidence to consider\n",
    "\n",
    "    Returns:\n",
    "    - indices of potentially mislabeled examples\n",
    "    - predicted labels\n",
    "    - confidence scores\n",
    "    \"\"\"\n",
    "    # Get probability predictions\n",
    "    proba_predictions = classifier.predict_proba(X_features)\n",
    "\n",
    "    # Get predicted class and confidence\n",
    "    pred_classes = np.argmax(proba_predictions, axis=1)\n",
    "    confidences = np.max(proba_predictions, axis=1)\n",
    "\n",
    "    # Find examples where prediction differs from label with high confidence\n",
    "    mislabeled_indices = np.where((pred_classes != y_labels) &\n",
    "                                  (confidences > confidence_threshold))[0]\n",
    "\n",
    "    return mislabeled_indices, pred_classes[mislabeled_indices], confidences[mislabeled_indices]\n",
    "\n",
    "\n",
    "# Example usage of the function\n",
    "potential_mislabeled, pred_labels, confidences = identify_mislabeled_faces(\n",
    "    svm_classifier_all, X_test_pca_all, y_test_all, confidence_threshold=0.9)\n",
    "\n",
    "print(f\"Found {len(potential_mislabeled)} potentially mislabeled faces with confidence > 0.9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba07ead2e11e9c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optional part of the assignment\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.manifold import TSNE\n",
    "# import matplotlib.offsetbox as offsetbox\n",
    "#\n",
    "# # For the optional part, we need to:\n",
    "# # - Generate 7-dimensional confidence vectors for face identity\n",
    "# # - Create a 2D embedding of these confidence vectors\n",
    "# # - Plot face images at their respective locations in the embedding\n",
    "#\n",
    "# # Step 1: Get confidence vectors for all test faces\n",
    "# # Using our SVM model (or any other model that performed best)\n",
    "# confidence_vectors = svm_classifier_all.predict_proba(X_test_pca_all)\n",
    "#\n",
    "# # Step 2: Apply t-SNE to get a 2D embedding of confidence vectors\n",
    "# tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "# embedding = tsne.fit_transform(confidence_vectors)\n",
    "#\n",
    "#\n",
    "# # Step 3: Plot the embedding with face images\n",
    "# def plot_embedding_with_faces(X_embedded, images, figsize=(20, 20), image_zoom=0.7):\n",
    "#     \"\"\"\n",
    "#     Plot a 2D embedding with actual face images as points.\n",
    "#\n",
    "#     Parameters:\n",
    "#     - X_embedded: 2D embedding coordinates\n",
    "#     - images: original face images to display\n",
    "#     - figsize: size of the figure\n",
    "#     - image_zoom: zoom factor for the images\n",
    "#     \"\"\"\n",
    "#     fig, ax = plt.subplots(figsize=figsize)\n",
    "#\n",
    "#     # Calculate bounds for the plot\n",
    "#     x_min, x_max = np.min(X_embedded[:, 0]), np.max(X_embedded[:, 0])\n",
    "#     y_min, y_max = np.min(X_embedded[:, 1]), np.max(X_embedded[:, 1])\n",
    "#\n",
    "#     # Add some margin\n",
    "#     margin = 0.1\n",
    "#     x_min -= (x_max - x_min) * margin\n",
    "#     x_max += (x_max - x_min) * margin\n",
    "#     y_min -= (y_max - y_min) * margin\n",
    "#     y_max += (y_max - y_min) * margin\n",
    "#\n",
    "#     # Set the bounds\n",
    "#     ax.set_xlim(x_min, x_max)\n",
    "#     ax.set_ylim(y_min, y_max)\n",
    "#\n",
    "#     # Determine the step size for showing images (to avoid overcrowding)\n",
    "#     # Show a maximum of 300 images to prevent overcrowding\n",
    "#     n_images = min(300, len(X_embedded))\n",
    "#     step = len(X_embedded) // n_images\n",
    "#\n",
    "#     # Plot the images at their embedded positions\n",
    "#     for i in range(0, len(X_embedded), step):\n",
    "#         # Get the face image\n",
    "#         img = images[i].reshape(48, 48)\n",
    "#\n",
    "#         # Create an OffsetImage\n",
    "#         imagebox = offsetbox.OffsetImage(img, zoom=image_zoom, cmap='gray')\n",
    "#\n",
    "#         # Create an AnnotationBbox\n",
    "#         ab = offsetbox.AnnotationBbox(\n",
    "#             imagebox,\n",
    "#             (X_embedded[i, 0], X_embedded[i, 1]),\n",
    "#             frameon=False,\n",
    "#             pad=0.0\n",
    "#         )\n",
    "#\n",
    "#         # Add the AnnotationBbox to the axes\n",
    "#         ax.add_artist(ab)\n",
    "#\n",
    "#     # Set up the plot\n",
    "#     ax.set_title(\"t-SNE Embedding of Face Images Based on Emotion Confidence\", fontsize=14)\n",
    "#     ax.set_xlabel(\"t-SNE Dimension 1\", fontsize=12)\n",
    "#     ax.set_ylabel(\"t-SNE Dimension 2\", fontsize=12)\n",
    "#     ax.grid(False)  # Remove grid for cleaner appearance\n",
    "#\n",
    "#     return fig, ax\n",
    "#\n",
    "#\n",
    "# # Create the embedding visualization with faces\n",
    "# fig, ax = plot_embedding_with_faces(embedding, X_test, figsize=(20, 20), image_zoom=0.5)\n",
    "# plt.savefig('face_embedding_tsne.png', dpi=200, bbox_inches='tight')\n",
    "# plt.show()\n",
    "#\n",
    "#\n",
    "# # Add color coding by predicted emotion\n",
    "# def plot_embedding_with_faces_colored(X_embedded, images, predictions, figsize=(20, 20), image_zoom=0.7):\n",
    "#     \"\"\"\n",
    "#     Plot a 2D embedding with actual face images as points, colored by predicted emotion.\n",
    "#\n",
    "#     Parameters:\n",
    "#     - X_embedded: 2D embedding coordinates\n",
    "#     - images: original face images to display\n",
    "#     - predictions: predicted emotion classes\n",
    "#     - figsize: size of the figure\n",
    "#     - image_zoom: zoom factor for the images\n",
    "#     \"\"\"\n",
    "#     fig, ax = plt.subplots(figsize=figsize)\n",
    "#\n",
    "#     # Calculate bounds for the plot\n",
    "#     x_min, x_max = np.min(X_embedded[:, 0]), np.max(X_embedded[:, 0])\n",
    "#     y_min, y_max = np.min(X_embedded[:, 1]), np.max(X_embedded[:, 1])\n",
    "#\n",
    "#     # Add some margin\n",
    "#     margin = 0.1\n",
    "#     x_min -= (x_max - x_min) * margin\n",
    "#     x_max += (x_max - x_min) * margin\n",
    "#     y_min -= (y_max - y_min) * margin\n",
    "#     y_max += (y_max - y_min) * margin\n",
    "#\n",
    "#     # Set the bounds\n",
    "#     ax.set_xlim(x_min, x_max)\n",
    "#     ax.set_ylim(y_min, y_max)\n",
    "#\n",
    "#     # Create scatterplot of all points with color coding\n",
    "#     scatter = ax.scatter(X_embedded[:, 0], X_embedded[:, 1],\n",
    "#                          c=predictions, alpha=0.1, s=3, cmap='tab10')\n",
    "#\n",
    "#     # Create a legend for the emotions\n",
    "#     legend_elements = [plt.Line2D([0], [0], marker='o', color='w',\n",
    "#                                   markerfacecolor=scatter.cmap,\n",
    "#                                   # scatter.norm(i),\n",
    "#                                   markersize=8, label=f'Emotion {i}') for i in range(len(np.unique(predictions)))]\n",
    "#     ax.legend(handles=legend_elements, title=\"Predicted Emotion\")\n",
    "#\n",
    "#     # Now, add the face images to the plot\n",
    "#     for i in range(0, len(X_embedded), step):\n",
    "#         img = images[i].reshape(48, 48)  # Assuming the face images are 48x48\n",
    "#         imagebox = offsetbox.OffsetImage(img, zoom=image_zoom, cmap='gray')\n",
    "#         ab = offsetbox.AnnotationBbox(imagebox, (X_embedded[i, 0], X_embedded[i, 1]), frameon=False, pad=0.0)\n",
    "#         ax.add_artist(ab)\n",
    "#\n",
    "#     # Set up the plot\n",
    "#     ax.set_title(\"t-SNE Embedding of Face Images Colored by Predicted Emotion\", fontsize=14)\n",
    "#     ax.set_xlabel(\"t-SNE Dimension 1\", fontsize=12)\n",
    "#     ax.set_ylabel(\"t-SNE Dimension 2\", fontsize=12)\n",
    "#     ax.grid(False)\n",
    "#\n",
    "#     return fig, ax\n",
    "#\n",
    "#\n",
    "# # Plot the embedding with face images colored by predicted emotions\n",
    "# # Assuming `y_pred` are the predicted labels from the classifier (e.g., SVM)\n",
    "# fig, ax = plot_embedding_with_faces_colored(embedding, X_test, y_pred, figsize=(20, 20), image_zoom=0.5)\n",
    "# plt.savefig('face_embedding_tsne_colored.png', dpi=200, bbox_inches='tight')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a187744df3b7a7c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-02-28T20:01:01.729930Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Optional part of the assignment\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.offsetbox as offsetbox\n",
    "\n",
    "# Step 1: Get confidence vectors for all test faces\n",
    "# Using our SVM model (or any other model that performed best)\n",
    "confidence_vectors = svm_classifier_all.predict_proba(X_test_pca_all)\n",
    "\n",
    "# Step 2: Apply t-SNE to get a 2D embedding of confidence vectors\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "embedding = tsne.fit_transform(confidence_vectors)\n",
    "\n",
    "\n",
    "# Step 3: Plot the embedding with face images\n",
    "def plot_embedding_with_faces(X_embedded, images, figsize=(20, 20), image_zoom=0.7):\n",
    "    \"\"\"\n",
    "    Plot a 2D embedding with actual face images as points.\n",
    "\n",
    "    Parameters:\n",
    "    - X_embedded: 2D embedding coordinates\n",
    "    - images: original face images to display\n",
    "    - figsize: size of the figure\n",
    "    - image_zoom: zoom factor for the images\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # Calculate bounds for the plot\n",
    "    x_min, x_max = np.min(X_embedded[:, 0]), np.max(X_embedded[:, 0])\n",
    "    y_min, y_max = np.min(X_embedded[:, 1]), np.max(X_embedded[:, 1])\n",
    "\n",
    "    # Add some margin\n",
    "    margin = 0.1\n",
    "    x_min -= (x_max - x_min) * margin\n",
    "    x_max += (x_max - x_min) * margin\n",
    "    y_min -= (y_max - y_min) * margin\n",
    "    y_max += (y_max - y_min) * margin\n",
    "\n",
    "    # Set the bounds\n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "\n",
    "    # Determine the step size for showing images (to avoid overcrowding)\n",
    "    # Show a maximum of 300 images to prevent overcrowding\n",
    "    n_images = min(300, len(X_embedded))\n",
    "    step = len(X_embedded) // n_images  # Define the step for image placement\n",
    "\n",
    "    # Plot the images at their embedded positions\n",
    "    for i in range(0, len(X_embedded), step):\n",
    "        # Get the face image\n",
    "        img = images[i].reshape(48, 48)\n",
    "\n",
    "        # Create an OffsetImage\n",
    "        imagebox = offsetbox.OffsetImage(img, zoom=image_zoom, cmap='gray')\n",
    "\n",
    "        # Create an AnnotationBbox\n",
    "        ab = offsetbox.AnnotationBbox(\n",
    "            imagebox,\n",
    "            (X_embedded[i, 0], X_embedded[i, 1]),\n",
    "            frameon=False,\n",
    "            pad=0.0\n",
    "        )\n",
    "\n",
    "        # Add the AnnotationBbox to the axes\n",
    "        ax.add_artist(ab)\n",
    "\n",
    "    # Set up the plot\n",
    "    ax.set_title(\"t-SNE Embedding of Face Images Based on Emotion Confidence\", fontsize=14)\n",
    "    ax.set_xlabel(\"t-SNE Dimension 1\", fontsize=12)\n",
    "    ax.set_ylabel(\"t-SNE Dimension 2\", fontsize=12)\n",
    "    ax.grid(False)  # Remove grid for cleaner appearance\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "# Create the embedding visualization with faces\n",
    "fig, ax = plot_embedding_with_faces(embedding, X_test, figsize=(20, 20), image_zoom=0.5)\n",
    "plt.savefig('face_embedding_tsne.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Add color coding by predicted emotion\n",
    "def plot_embedding_with_faces_colored(X_embedded, images, predictions, figsize=(20, 20), image_zoom=0.7):\n",
    "    \"\"\"\n",
    "    Plot a 2D embedding with actual face images as points, colored by predicted emotion.\n",
    "\n",
    "    Parameters:\n",
    "    - X_embedded: 2D embedding coordinates\n",
    "    - images: original face images to display\n",
    "    - predictions: predicted emotion classes\n",
    "    - figsize: size of the figure\n",
    "    - image_zoom: zoom factor for the images\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # Calculate bounds for the plot\n",
    "    x_min, x_max = np.min(X_embedded[:, 0]), np.max(X_embedded[:, 0])\n",
    "    y_min, y_max = np.min(X_embedded[:, 1]), np.max(X_embedded[:, 1])\n",
    "\n",
    "    # Add some margin\n",
    "    margin = 0.1\n",
    "    x_min -= (x_max - x_min) * margin\n",
    "    x_max += (x_max - x_min) * margin\n",
    "    y_min -= (y_max - y_min) * margin\n",
    "    y_max += (y_max - y_min) * margin\n",
    "\n",
    "    # Set the bounds\n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "\n",
    "    # Determine the step size for showing images (to avoid overcrowding)\n",
    "    # Show a maximum of 300 images to prevent overcrowding\n",
    "    n_images = min(300, len(X_embedded))\n",
    "    step = len(X_embedded) // n_images  # Define the step for image placement\n",
    "\n",
    "    # Create scatterplot of all points with color coding\n",
    "    scatter = ax.scatter(X_embedded[:, 0], X_embedded[:, 1],\n",
    "                         c=predictions, alpha=0.1, s=3, cmap='tab10')\n",
    "\n",
    "    # Create a legend for the emotions\n",
    "    legend_elements = [plt.Line2D([0], [0], marker='o', color='w',\n",
    "                                  markerfacecolor=scatter.cmap(scatter.norm(i)),\n",
    "                                  markersize=8, label=f'Emotion {i}') for i in range(\n",
    "        len(np.unique(predictions)))]\n",
    "    ax.legend(handles=legend_elements, title=\"Predicted Emotion\")\n",
    "\n",
    "    # Now, add the face images to the plot\n",
    "    for i in range(0, len(X_embedded), step):\n",
    "        img = images[i].reshape(48, 48)  # Assuming the face images are 48x48\n",
    "        imagebox = offsetbox.OffsetImage(img, zoom=image_zoom, cmap='gray')\n",
    "        ab = offsetbox.AnnotationBbox(imagebox, (X_embedded[i, 0], X_embedded[i, 1]), frameon=False, pad=0.0)\n",
    "        ax.add_artist(ab)\n",
    "\n",
    "    # Set up the plot\n",
    "    ax.set_title(\"t-SNE Embedding of Face Images Colored by Predicted Emotion\", fontsize=14)\n",
    "    ax.set_xlabel(\"t-SNE Dimension 1\", fontsize=12)\n",
    "    ax.set_ylabel(\"t-SNE Dimension 2\", fontsize=12)\n",
    "    ax.grid(False)\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "# y_pred_svm_all\n",
    "# Get the predicted labels (y_pred) from your classifier (e.g., SVM)\n",
    "# y_pred = svm_classifier_all.predict(X_test_pca_all)  # Assuming svm_classifier_all is your trained model\n",
    "\n",
    "# Plot the embedding with face images colored by predicted emotions\n",
    "fig, ax = plot_embedding_with_faces_colored(embedding, X_test, y_pred_svm_all, figsize=(20, 20), image_zoom=0.5)\n",
    "plt.savefig('face_embedding_tsne_colored.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9186c6f0313a5813",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fenv)",
   "language": "python",
   "name": "fenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
